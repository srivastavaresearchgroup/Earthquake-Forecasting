{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "\n",
    "import h5py\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import datetime as d\n",
    "from collections import Counter\n",
    "\n",
    "import obspy\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "import sys\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\n",
    "    'name'       : 'Japan',\n",
    "    'center'     : [38.0, 140.0],\n",
    "    'delta'      : 15.0, \n",
    "    'min_mag'    : 0.0,\n",
    "    'start_date' : '1964-01-01', \n",
    "    'end_date'   : '2019-01-01',\n",
    "    'client'     : 'ISC'\n",
    "}\n",
    "\n",
    "figname = '{}_{}_'.format(event['name'], event['client'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_pickle('Japan_ISC_Complete_NaN.pkl')\n",
    "\n",
    "catalog_np = np.array(catalog.iloc[:,4:])\n",
    "catalog_mags = np.nanmax(catalog_np, axis=1)\n",
    "catalog_dates = np.array(catalog.iloc[:, 0])\n",
    "catalog_coords = np.array(catalog.iloc[:,1:3])\n",
    "catalog_depth = np.array(catalog.iloc[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ms2Mw(Ms):\n",
    "    return np.where(\n",
    "        Ms == Ms, \n",
    "        np.where(Ms < 6.15, 0.65 * Ms + 2.2, Ms - 0.02), # 3.0 - 6.1 | 6.2 - 8.0\n",
    "        np.nan) \n",
    "    \n",
    "def mb2Mw(mb):\n",
    "    return 0.85*mb + 1.02\n",
    "    \n",
    "def M2Mw(M):\n",
    "    return np.where(\n",
    "        M == M, \n",
    "        np.where(M < 5.55, 0.58*M+2.25, 0.97*M+0.04), # 3-5.5 | 5.6 - 8.2\n",
    "        np.nan) \n",
    "\n",
    "\n",
    "def fillWith(Mw, Mn):\n",
    "    return np.where(Mn==Mn, Mn, Mw)\n",
    "\n",
    "def doMwConversion():\n",
    "    Mw = M2Mw(np.array(catalog_np[:, 39]))\n",
    "\n",
    "    Mw = fillWith(Mw, M2Mw(np.array(catalog_np[:, 42])))\n",
    "    Mw = fillWith(Mw, M2Mw(np.array(catalog_np[:, 35])))\n",
    "    Mw = fillWith(Mw, mb2Mw(np.array(catalog_np[:, 0])))\n",
    "    Mw = fillWith(Mw, Ms2Mw(np.array(catalog_np[:, 5])))\n",
    "\n",
    "    return Mw \n",
    "\n",
    "\n",
    "def doMwConversionMix():\n",
    "    Mw = M2Mw(np.array(catalog_np[:, 39]))\n",
    "\n",
    "    Mw = fillWith(Mw, np.array(catalog_np[:, 42]))\n",
    "    Mw = fillWith(Mw, np.array(catalog_np[:, 35]))\n",
    "    Mw = fillWith(Mw, np.array(catalog_np[:, 0]))\n",
    "    Mw = fillWith(Mw, np.array(catalog_np[:, 5]))\n",
    "\n",
    "    return Mw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_mags = doMwConversion()\n",
    "\n",
    "catalog_mags_mix = doMwConversionMix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcB(bmagsin, bmin=3):  \n",
    "    bmags = bmagsin[~np.isnan(bmagsin)]\n",
    "    bmags = bmags[bmags>=bmin]\n",
    "    if len(bmags) < 2: \n",
    "        return np.nan\n",
    "    b1 = np.sum(bmags)/len(bmags) - np.min(bmags)\n",
    "    if b1 == 0.0: \n",
    "        return np.nan \n",
    "    return 1.0/b1*np.log10(np.e), 1.96/np.sqrt(len(bmags))/b1*np.log10(np.e) # Last part is the uncertainty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earthquake Animation, red x black bock starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Depth in km:\n",
    "depth0 = 0\n",
    "depth1 = 70\n",
    "\n",
    "# Relations from NARW-2005.pdf\n",
    "# mb: 0\n",
    "# MS: 5\n",
    "# ML: 35\n",
    "# M:  39\n",
    "# MV: 42\n",
    "\n",
    "def Ms2Mw(Ms):\n",
    "    return np.where(\n",
    "        Ms == Ms, \n",
    "        np.where(Ms < 6.15, 0.65 * Ms + 2.2, Ms - 0.02), # 3.0 - 6.1 | 6.2 - 8.0\n",
    "        np.nan) \n",
    "    \n",
    "def mb2Mw(mb):\n",
    "    return 0.85*mb + 1.02\n",
    "    \n",
    "def M2Mw(M):\n",
    "    return np.where(\n",
    "        M == M, \n",
    "        np.where(M < 5.55, 0.58*M+2.25, 0.97*M+0.04), # 3-5.5 | 5.6 - 8.2\n",
    "        np.nan) \n",
    "\n",
    "\n",
    "def fillWith(Mw, Mn):\n",
    "    return np.where(Mn==Mn, Mn, Mw)\n",
    "    \n",
    "Mw = M2Mw(np.array(catalog_np[:, 39]))\n",
    "\n",
    "Mw = fillWith(Mw, M2Mw(np.array(catalog_np[:, 42])))\n",
    "Mw = fillWith(Mw, M2Mw(np.array(catalog_np[:, 35])))\n",
    "Mw = fillWith(Mw, mb2Mw(np.array(catalog_np[:, 0])))\n",
    "Mw = fillWith(Mw, Ms2Mw(np.array(catalog_np[:, 5])))\n",
    "\n",
    "\n",
    "\n",
    "catalog_mags = Mw # Nans are skipped with >= step \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth0 = -1\n",
    "depth1 = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDayBlock(e):\n",
    "    long_min = 120.0\n",
    "    long_max = 150.0\n",
    "    lat_min  = 20.0\n",
    "    lat_max  = 50.0\n",
    "    gridsize = 0.1\n",
    "    dr = 0.25 # Radius for b calculation\n",
    "    \n",
    "    def calcB(bmags):  \n",
    "        if len(bmags) < 2: \n",
    "            return np.nan\n",
    "        b1 = np.sum(bmags)/len(bmags) - np.min(bmags)\n",
    "        if b1 == 0.0: \n",
    "            return np.nan \n",
    "        return 1.0/b1*np.log10(np.e) # 1.96/np.sqrt(len(bmags))/b1*np.log10(np.e) # Last part is the uncertainty\n",
    "    \n",
    "    # make selection\n",
    "    sel = np.logical_and(\n",
    "            np.logical_and(\n",
    "                catalog_dates > e - np.timedelta64(513, 'D'),\n",
    "                catalog_dates < e - np.timedelta64(1, 'D')),\n",
    "            np.logical_and(catalog_depth/1000 <= depth1, \n",
    "                           catalog_depth/1000 > depth0))\n",
    "    sel = np.logical_and(sel, catalog_mags == catalog_mags) # Filter out nan Magnitudes\n",
    "    s_long = catalog_coords[sel, 1]\n",
    "    s_lats = catalog_coords[sel, 0]\n",
    "    s_mags = catalog_mags[sel]\n",
    "    s_date = catalog_dates[sel]\n",
    "    \n",
    "    #calculate points:\n",
    "    px, py = np.meshgrid(np.arange(long_min+0.05, long_max, 0.1), np.arange( lat_min+0.05,  lat_max, 0.1))\n",
    "    points = np.reshape(np.append(px, py), (-1,2), order='F')\n",
    "    sel_points = np.array([((p[0]-s_long)**2 + (p[1]-s_lats)**2) < dr for p in points])\n",
    "  \n",
    "    b_values = np.zeros((300*300), dtype='float16')\n",
    "    n_values = np.zeros((300*300), dtype='int')\n",
    "    for k, sel_point in enumerate(sel_points):\n",
    "        k_mags = s_mags[sel_point]\n",
    "        b_values[k] = calcB(k_mags)\n",
    "        n_values[k] = len(k_mags)\n",
    "        \n",
    "    print('Done With {}!'.format(e), end='\\r')\n",
    "    return np.reshape(b_values, (300,300)), np.reshape(n_values, (300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processDayMetadata(e):\n",
    "    long_min = 120.0\n",
    "    long_max = 150.0\n",
    "    lat_min  = 20.0\n",
    "    lat_max  = 50.0\n",
    "    gridsize = 0.1\n",
    "    dr = 0.25 # Radius for b calculation\n",
    "    \n",
    "    # make selection\n",
    "    sel = np.logical_and(\n",
    "            np.logical_and(\n",
    "                catalog_dates > e - np.timedelta64(1, 'D'),\n",
    "                catalog_dates < e),\n",
    "            np.logical_and(catalog_depth/1000 <= depth1, \n",
    "                           catalog_depth/1000 > depth0))\n",
    "    sel = np.logical_and(sel, catalog_mags == catalog_mags) # Filter out nan Magnitudes\n",
    "    s_long = catalog_coords[sel, 1]\n",
    "    s_lats = catalog_coords[sel, 0]\n",
    "    s_mags = catalog_mags[sel]\n",
    "    s_depth = catalog_depth[sel]  ### JKC: sel was missing here!?!?!?!?!?!?!\n",
    "\n",
    "    gix = lambda a : min(int((a - long_min) / gridsize), 299)\n",
    "    giy = lambda a : min(int((a - lat_min) / gridsize), 299)\n",
    "    \n",
    "    depth = np.ones((300,300), dtype='float32')*np.nan\n",
    "    maxmag = np.ones((300,300), dtype='float16') * -1.0\n",
    "\n",
    "    for i in range(len(s_long)):\n",
    "        if maxmag[gix(s_long[i]), giy(s_lats[i])] < s_mags[i]:\n",
    "            maxmag[gix(s_long[i]), giy(s_lats[i])] = s_mags[i] \n",
    "            depth[gix(s_long[i]), giy(s_lats[i])] = s_depth[i]\n",
    "    \n",
    "    \n",
    "    #print('Done With {}!'.format(e), end='\\r')\n",
    "    return maxmag, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processDayBlock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_654064/339812250.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# do not use more than 60 or RAM will run out!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessDayBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processDayBlock' is not defined"
     ]
    }
   ],
   "source": [
    "# Code for full regeneration of file\n",
    "\n",
    "fname = 'ML_Tiles_000to070_FullBlock_sliced.hdf5'\n",
    "dates = np.arange('2000-01-01', '2020-01-01', dtype='datetime64[D]') # Full block starts at 2000-01-01, what was i thinking\n",
    "\n",
    "t1 = time.time()\n",
    "with Pool(20) as p: # do not use more than 60 or RAM will run out!\n",
    "    res = p.map(processDayBlock, dates)\n",
    "    f1 = h5py.File(fname, 'a')\n",
    "    for i, r in enumerate(res):\n",
    "        g1 = f1.create_group('day_{:04d}_{}'.format(i, str(dates[i])))\n",
    "        g1.create_dataset('b_value', r[0].shape, dtype='float16', data=r[0])\n",
    "        g1.create_dataset('n_eq', r[1].shape, dtype='int16', data=r[1])\n",
    "    f1.close()\n",
    "    t2 = time.time()\n",
    "    res = p.map(processDayMetadata, dates)\n",
    "    f1 = h5py.File(fname, 'a')\n",
    "    for i, r in enumerate(res):\n",
    "        g1 = f1['day_{:04d}_{}'.format(i, str(dates[i]))]\n",
    "        g1.create_dataset('maxmag', r[0].shape, dtype='float16', data=r[0])\n",
    "        g1.create_dataset('depth', r[1].shape, dtype='float32', data=r[1])\n",
    "    f1.close()\n",
    "    t2 = time.time()\n",
    "\n",
    "\n",
    "print('Calculation: {} s'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation: 260.14920377731323 s\n"
     ]
    }
   ],
   "source": [
    "# Update faulty depth\n",
    "\n",
    "fname = 'ML_Tiles_000to070_FullBlock_sliced.hdf5'\n",
    "dates = np.arange('2000-01-01', '2020-01-01', dtype='datetime64[D]') # Full block starts at 2000-01-01, what was i thinking\n",
    "\n",
    "t1 = time.time()\n",
    "with Pool(20) as p: # do not use more than 60 or RAM will run out!\n",
    "    res = p.map(processDayMetadata, dates)\n",
    "    f1 = h5py.File(fname, 'a')\n",
    "    for i, r in enumerate(res):\n",
    "        g1 = f1['day_{:04d}_{}'.format(i, str(dates[i]))]\n",
    "        g1['maxmag'][...] = r[0]\n",
    "        g1['depth'][...] = r[1]\n",
    "        #g1.create_dataset('maxmag', r[0].shape, dtype='float16', data=r[0])\n",
    "        #g1.create_dataset('depth', r[1].shape, dtype='float32', data=r[1])\n",
    "    f1.close()\n",
    "    t2 = time.time()\n",
    "\n",
    "\n",
    "print('Calculation: {} s'.format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = h5py.File('ML_Tiles_000to070_FullBlock.hdf5', 'w')\n",
    "f3 = h5py.File('ML_Tiles_000to070_FullBlock_sliced.hdf5', 'r')\n",
    "\n",
    "dates = np.arange('2000-01-01', '2020-01-01', dtype='datetime64[D]')\n",
    "\n",
    "keys = f3.keys()\n",
    "keys = sorted(np.array([str(key) for key in keys]))\n",
    "\n",
    "fullBlock_b = np.zeros((len(keys), 300, 300), dtype='float16')\n",
    "fullBlock_n = np.zeros((len(keys), 300, 300), dtype=int)\n",
    "fullBlock_maxmag = np.zeros((len(keys), 300, 300), dtype='float16')\n",
    "fullBlock_depth = np.zeros((len(keys), 300, 300), dtype='float32')\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    fullBlock_b[i] = np.array(f3[key+'/b_value'])\n",
    "    fullBlock_n[i] = np.array(f3[key+'/n_eq'])\n",
    "    fullBlock_maxmag[i] = np.array(f3[key+'/maxmag']).T\n",
    "    fullBlock_depth[i]  = np.array(f3[key+'/depth']).T\n",
    "f3.close()\n",
    "\n",
    "\n",
    "\n",
    "f2.create_dataset('b_value', fullBlock_b.shape, dtype='float16', data=fullBlock_b)\n",
    "f2.create_dataset('n_eq', fullBlock_n.shape, dtype='int16', data=fullBlock_n)\n",
    "f2.create_dataset('maxmag', fullBlock_b.shape, dtype='float16', data=fullBlock_maxmag)\n",
    "f2.create_dataset('depth', fullBlock_n.shape, dtype='float32', data=fullBlock_depth)\n",
    "f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m noeqarray\n\u001b[0;32m---> 21\u001b[0m noeqarray \u001b[38;5;241m=\u001b[39m \u001b[43mmakeNoEQArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m f2 \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mML_Tiles_000to070_FullBlock.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m f2\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoEQArray\u001b[39m\u001b[38;5;124m'\u001b[39m, noeqarray\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mnoeqarray)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmakeNoEQArray\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m, maxm_loc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m16\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m16\u001b[39m, maxm_loc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxm_loc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m4.5\u001b[39m:\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(n_eq_avg[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m7\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m:j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m8\u001b[39m, k\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m:k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m8\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m     17\u001b[0m                 noeqarray[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m512\u001b[39m, j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m16\u001b[39m, k\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m16\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2705\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2591\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2592\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2594\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jupyterlab_venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:87\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f2 = h5py.File('ML_Tiles_000to070_FullBlock.hdf5', 'r')\n",
    "bval_loc = np.array(f2['b_value'])\n",
    "n_eq_avg = np.array(f2['n_eq'])\n",
    "maxm_loc = np.array(f2['maxmag'])\n",
    "dept_avg = np.array(f2['depth'])\n",
    "f2.close()\n",
    "\n",
    "\n",
    "def makeNoEQArray():\n",
    "    noeqarray = np.zeros(maxm_loc.shape-np.array([512, 32,32]), dtype=bool)\n",
    "    for i in range(512, maxm_loc.shape[0]):\n",
    "        for j in range(16, maxm_loc.shape[1]-16):\n",
    "            for k in range(16, maxm_loc.shape[2]-16):\n",
    "                if np.max(maxm_loc[i-7:i+7, j-8:j+8, k-8:k+8]) < 4.5:\n",
    "                    if np.mean(n_eq_avg[i-7:i+7, j-8:j+8, k-8:k+8]) > 10:\n",
    "                        noeqarray[i-512, j-16, k-16] = True\n",
    "        print(i, end='\\r')\n",
    "    return noeqarray\n",
    "\n",
    "noeqarray = makeNoEQArray()\n",
    "\n",
    "f2 = h5py.File('ML_Tiles_000to070_FullBlock.hdf5', 'a')\n",
    "f2.create_dataset('NoEQArray', noeqarray.shape, dtype='float16', data=noeqarray)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy noeqarray over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read old data\n"
     ]
    }
   ],
   "source": [
    "fold = h5py.File('ML_Tiles_000to070_FullBlock_old.hdf5', 'r')\n",
    "noeqarray = np.array(fold['NoEQArray'])\n",
    "fold.close()\n",
    "\n",
    "print('Read old data')\n",
    "\n",
    "f2 = h5py.File('ML_Tiles_000to070_FullBlock.hdf5', 'a')\n",
    "f2.create_dataset('NoEQArray', noeqarray.shape, dtype='float16', data=noeqarray)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Create Block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = h5py.File('ML_Tiles_000to070_FullBlock.hdf5', 'r')\n",
    "\n",
    "bval_avg = np.mean(f2['b_value'], axis=0)\n",
    "n_eq_avg = np.mean(f2['n_eq'], axis=0)\n",
    "maxm_avg = np.mean(f2['maxmag'], axis=0)\n",
    "dept_avg = np.nanmean(f2['depth'], axis=0)\n",
    "\n",
    "f2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
